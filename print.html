<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Bagua Tutorials</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="Guide on how to use Bagua, a deep learning distributed training framework">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="installation.html"><strong aria-hidden="true">2.</strong> Installation</a></li><li class="chapter-item expanded "><a href="getting-started/index.html"><strong aria-hidden="true">3.</strong> Getting Started</a></li><li class="chapter-item expanded "><a href="algorithms/index.html"><strong aria-hidden="true">4.</strong> Algorithms</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="algorithms/decentralized.html"><strong aria-hidden="true">4.1.</strong> Decentralized Parallel Stochastic Gradient</a></li></ol></li><li class="chapter-item expanded "><a href="faq_troubleshooting.html"><strong aria-hidden="true">5.</strong> FAQ and Troubleshooting</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Bagua Tutorials</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>Bagua is a distributed training utility developed by Kuaishou Technology and DS3 Lab. It aims to provide a system abstraction that is both flexible and performant to support state-of-the-art system relaxation techniques of distributed training. Powered by the new system design, Bagua has a great ability to implement and extend various state-of-the-art distributed learning algorithms. Researchers can easily develop new distributed training algorithms based on bagua, <em>without sacrificing system performance</em>.</p>
<p>Currently bagua has integrated primitives like <em>Centralized Synchronous Communication (AllReduce)</em>, <em>Decentralized Synchronous Communication</em>, <em>Low Precision Communication</em> and many more. Its effectiveness has been verified in various scenarios, including VGG-16 and ResNet-50 on ImageNet, Bert Large on SQuAD and many industrial applications at Kuaishou. </p>
<h1 id="links"><a class="header" href="#links">Links</a></h1>
<ul>
<li><a href="https://github.com/BaguaSys/bagua">Bagua</a></li>
<li><a href="https://baguasys.github.io/tutorials">Bagua Tutorials</a></li>
<li><a href="https://bagua.readthedocs.io/">Bagua API Documentation</a></li>
</ul>
<h1 id="installation"><a class="header" href="#installation">Installation</a></h1>
<p>To install Bagua, besides your deep learning framework (like <a href="https://pytorch.org/get-started/locally/">PyTorch</a>
), you need the following libraries installed on your system:</p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads">CUDA Toolkit</a>, with CUDA version &gt;= 10.1</li>
<li><a href="https://www.rust-lang.org/tools/install">Rust Compiler</a></li>
</ul>
<p>We provide an automatic installation script for Linux. Just run the following command to install all dependencies and Bagua:</p>
<pre><code class="language-python">curl -Ls https://raw.githubusercontent.com/BaguaSys/bagua/master/install.sh | sudo bash
</code></pre>
<p>If you already installed the dependencies, you can install bagua python package with the following commands:</p>
<p>Install release version:</p>
<pre><code class="language-shell">python3 -m pip install bagua
</code></pre>
<p>Install develop version:</p>
<pre><code class="language-shell">python3 -m pip install git+https://github.com/BaguaSys/bagua.git
</code></pre>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>Letâ€™s start our Bagua journey!</p>
<h1 id="migrate-from-your-existing-single-gpu-training-code"><a class="header" href="#migrate-from-your-existing-single-gpu-training-code">Migrate from your existing single GPU training code</a></h1>
<p>To use <code>Bagua</code>, you need make the following changes on your training code:</p>
<p>First, import bagua and make your script distributed aware:</p>
<pre><code class="language-python">import bagua.torch_api as bagua
torch.cuda.set_device(bagua.get_local_rank())
bagua.init_process_group()
</code></pre>
<p>Then, use torch's distributed sampler for your data loader:</p>
<pre><code class="language-python">train_dataset = ...
test_dataset = ...

train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,
    num_replicas=bagua.get_world_size(), rank=bagua.get_rank())

train_loader = torch.utils.data.DataLoader(
    train_dataset,
    batch_size=batch_size,
    shuffle=(train_sampler is None),
    sampler=train_sampler,
)

test_loader = torch.utils.data.DataLoader(test_dataset, ...)
</code></pre>
<p>Finally, wrap you model and optimizer with bagua by adding one line of code to your original script:</p>
<pre><code class="language-python"># define your model and optimizer
model = ...
model = model.cuda()
optimizer = ...

# wrap your model and optimizer with bagua
model, optimizer = bagua.bagua_init(
    model, optimizer, distributed_algorithm=&quot;allreduce&quot;
)
</code></pre>
<p>More examples can be found <a href="https://github.com/BaguaSys/examples">here</a>.</p>
<h1 id="launch-job"><a class="header" href="#launch-job">Launch job</a></h1>
<p>Bagua has a built-in tool <code>bagua.distributed.launch</code> to launch jobs, whose usage is similar to Pytorch <code>torch.distributed.launch</code>.</p>
<p>We introduce how to start distributed training in the following sections.</p>
<h2 id="single-node-multi-process-training"><a class="header" href="#single-node-multi-process-training">Single node multi-process training</a></h2>
<pre><code class="language-shell">$ python -m bagua.distributed.launch --nproc_per_node=8 \
  your_training_script.py (--arg1 --arg2 ...)
</code></pre>
<h2 id="multi-node-multi-process-training-eg-two-nodes"><a class="header" href="#multi-node-multi-process-training-eg-two-nodes">Multi-node multi-process training (e.g. two nodes)</a></h2>
<p><strong>Node 1</strong>: <em>(IP: 192.168.1.1, and has a free port: 1234)</em></p>
<pre><code class="language-shell">$ python -m bagua.distributed.launch --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=&quot;192.168.1.1&quot; --master_port=1234  your_training_script.py (--arg1 --arg2 ...)
</code></pre>
<p><strong>Node 2</strong>:</p>
<pre><code class="language-shell">$ python -m bagua.distributed.launch --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=&quot;192.168.1.1&quot; --master_port=1234 your_training_script.py (--arg1 --arg2 ...)
</code></pre>
<blockquote>
<p><em>Tips</em>:</p>
<p>If you need some preprocessing work, you can include them in your bash script and launch job by adding <code>--no_python</code> to your command.</p>
<pre><code class="language-shell">python -m bagua.distributed.launch --no_python --nproc_per_node=8 bash your_bash_script.sh
</code></pre>
</blockquote>
<h1 id="algorithms"><a class="header" href="#algorithms">Algorithms</a></h1>
<h1 id="frequently-asked-questions-and-troubleshooting"><a class="header" href="#frequently-asked-questions-and-troubleshooting">Frequently Asked Questions and Troubleshooting</a></h1>
<h2 id="nccl_error_invalid_argument"><a class="header" href="#nccl_error_invalid_argument"><code>NCCL_ERROR_INVALID_ARGUMENT</code></a></h2>
<p>Usually this is caused by the library version conflict, try updating to <code>torch&gt;=1.7.0</code>.</p>
<h2 id="error-when-installing-rust"><a class="header" href="#error-when-installing-rust">Error when installing rust</a></h2>
<p>If you see some error like the message below, just clean the original installation record first by <code>rm -rf /root/.rustup</code> and reinstall.</p>
<pre><code class="language-shell">$ error: could not rename component file from '/root/.rustup/toolchains/stable-x86_64-unknown-linux-gnu/share/doc/cargo' to '/root/.rustup/tmp/m74fkrv0gv6708f6_dir/bk'error: caused by: other os error.
</code></pre>
<h2 id="out-of-memory-when-using-the-quantize-algorithm"><a class="header" href="#out-of-memory-when-using-the-quantize-algorithm">Out of memory when using the quantize algorithm</a></h2>
<p>The quantize algorithm compresses the communication content and requires a certain amount of additional memory. Reduce the batch size appropriately.</p>
<h2 id="hang-when-running-a-distributed-program"><a class="header" href="#hang-when-running-a-distributed-program">Hang when running a distributed program</a></h2>
<p>You can try to check whether the machine has multiple network cards, and use command <code>NCCL_SOCKET_IFNAME=network card name (such as eth01)</code> to specify the network card. Card information can be determined by command <code>ls /sys/class/net/</code>.</p>
<h2 id="after-increasing-batch-size-by-distributed-training-model-perfomance-decreases"><a class="header" href="#after-increasing-batch-size-by-distributed-training-model-perfomance-decreases">After increasing batch size by distributed training, model perfomance decreases</a></h2>
<p>Some tricks you can try:</p>
<ol>
<li>Train more epochs and increase the number of training iterations to 0.2-0.3 times more than the original.</li>
<li>Scale the learning rate. If the total batch size of distributed training is increased by N times compared with the original, the learning rate (lr) of multi-machine multi-card training should also increased by N times and becomes N*lr.</li>
<li>Learning rate warmup. Perform a Gradual learning rate warmup for several epochs (see also <a href="https://arxiv.org/pdf/1706.02677.pdf">Accurate, Large Minibatch SGD:
Training ImageNet in 1 Hour</a>).</li>
</ol>
<h2 id="the-loss-drops-slowly-when-using-the-decentralized-algorithm"><a class="header" href="#the-loss-drops-slowly-when-using-the-decentralized-algorithm">The loss drops slowly when using the decentralized algorithm</a></h2>
<p>Decentralized algorithms often need a larger learning rate compared to other algorithms.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
